{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70efacba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb6eac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract text from CV using OCR\n",
    "def extract_text_from_cv(cv_image):\n",
    "    # Use OCR (Optical Character Recognition) to extract text from CV image\n",
    "    # Replace this with your preferred OCR library or API\n",
    "    text = \"Sample text extracted from CV image using OCR\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ecf298b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform sentiment analysis on text\n",
    "def perform_sentiment_analysis(text):\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    sentiment_score = sia.polarity_scores(text)\n",
    "    return sentiment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c888bb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess text data\n",
    "def preprocess_text(text):\n",
    "    # Perform text preprocessing tasks such as tokenization, removing stopwords, etc.\n",
    "    # Replace this with your preferred text preprocessing techniques\n",
    "    preprocessed_text = \"Sample preprocessed text\"\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "256042a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_features(text):\n",
    "    # You should implement logic to extract all relevant features from the text\n",
    "    # For example, using NLP techniques or any other relevant method\n",
    "    text_features = np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6])  # Sample feature vector\n",
    "    return text_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9c87d0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract additional features from text data\n",
    "def extract_additional_features(text):\n",
    "    # Implement feature extraction logic to obtain additional features\n",
    "    additional_features = np.array([0.4, 0.5])  # Sample additional features\n",
    "    return additional_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0195144a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to combine existing and additional features\n",
    "def combine_features(existing_features, additional_features):\n",
    "    # Concatenate existing and additional features\n",
    "    combined_features = np.concatenate((existing_features, additional_features))\n",
    "    return combined_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8a5c7e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess text data and extract features\n",
    "def preprocess_and_extract_features(text):\n",
    "    # Preprocess text (if needed)\n",
    "    preprocessed_text = preprocess_text(text)\n",
    "    \n",
    "    # Extract existing features\n",
    "    existing_features = extract_text_features(preprocessed_text)\n",
    "    \n",
    "    return existing_features  # Return only existing features as we don't need additional features for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "95c2000b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update training data to include additional features\n",
    "def update_training_data(X):\n",
    "    # Iterate through each text data point and extract additional features\n",
    "    additional_features_list = []\n",
    "    for text in X:\n",
    "        additional_features = extract_additional_features(text)\n",
    "        additional_features_list.append(additional_features)\n",
    "    \n",
    "    # Combine existing features with additional features\n",
    "    X_updated = np.concatenate((X, additional_features_list), axis=1)\n",
    "    \n",
    "    return X_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5c853e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train personality prediction model\n",
    "def train_personality_prediction_model(X, y):\n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train a RandomForestClassifier (or any other ML model) on the data\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d079b942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict personality traits from CV\n",
    "def predict_personality_traits(cv_text, model):\n",
    "    # Extract features from CV text\n",
    "    cv_features = preprocess_and_extract_features(cv_text)\n",
    "    \n",
    "    # Predict personality traits using the trained model\n",
    "    personality_traits = model.predict([cv_features])\n",
    "    \n",
    "    return personality_traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "68c36475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load pre-trained personality prediction model\n",
    "def load_trained_model(model_path):\n",
    "    # Load the trained model from disk\n",
    "    model = joblib.load(model_path)  # Assuming you saved the model using joblib\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1e0829e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to analyze CV image and predict personality traits\n",
    "def analyze_cv_image(cv_image_path, model):\n",
    "    # Read CV image using OpenCV\n",
    "    cv_image = cv2.imread(cv_image_path)\n",
    "    \n",
    "    # Extract text from CV image\n",
    "    cv_text = extract_text_from_cv(cv_image)\n",
    "    \n",
    "    # Perform sentiment analysis on CV text\n",
    "    sentiment_score = perform_sentiment_analysis(cv_text)\n",
    "    \n",
    "    # Preprocess CV text\n",
    "    preprocessed_text = preprocess_text(cv_text)\n",
    "    \n",
    "    # Predict personality traits from preprocessed text\n",
    "    personality_traits = predict_personality_traits(preprocessed_text, model)\n",
    "    \n",
    "    return sentiment_score, personality_traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2591bc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to analyze CV using reinforcement learning\n",
    "def analyze_cv_rl(cv_text):\n",
    "    # Define and train a reinforcement learning model\n",
    "    # Replace this with your reinforcement learning code\n",
    "    model = Sequential([\n",
    "        Dense(128, input_shape=(len(cv_text),), activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(5, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "    \n",
    "    # Use the trained reinforcement learning model to predict personality traits\n",
    "    personality_traits = model.predict(cv_text)\n",
    "    \n",
    "    return personality_traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c7c86fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  dependable       0.29      0.26      0.27        31\n",
      " extraverted       0.32      0.28      0.30        32\n",
      "      lively       0.26      0.41      0.32        22\n",
      " responsible       0.22      0.18      0.20        22\n",
      "     serious       0.35      0.34      0.35        35\n",
      "\n",
      "    accuracy                           0.30       142\n",
      "   macro avg       0.29      0.29      0.29       142\n",
      "weighted avg       0.30      0.30      0.29       142\n",
      "\n",
      "Sentiment Score: {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "Predicted Personality Traits: ['dependable']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Load CV data (if available)\n",
    "    cv_data = pd.read_csv(\"sentiment_data.csv\")  # Replace \"sentiment_data.csv\" with your CV dataset file\n",
    "    \n",
    "    # Extract features and labels from CV data\n",
    "    X = cv_data[[\"Age\", \"openness\",\"neuroticism\",\"conscientiousness\",\"agreeableness\",\"extraversion\"]]  # Corrected to use a list instead of a tuple\n",
    "    y = cv_data[\"Personality (Class label)\"]\n",
    "    \n",
    "    # Train personality prediction model\n",
    "    model = train_personality_prediction_model(X, y)\n",
    "    \n",
    "    # Save the trained model to a file\n",
    "    joblib.dump(model, 'trained_model.pkl')\n",
    "    \n",
    "    # Example usage: Analyze CV image\n",
    "    cv_image_path = \"sample.jpg\"  # Replace with path to your CV image\n",
    "    sentiment_score, personality_traits = analyze_cv_image(cv_image_path, model)\n",
    "    print(\"Sentiment Score:\", sentiment_score)\n",
    "    print(\"Predicted Personality Traits:\", personality_traits)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
